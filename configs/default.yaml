action: train # train or test
name: firstTry # name of the experiment needed for the logs
modality: ["RGB"] # modality used
total_batch: 128 # total batch size if training is done with gradient accumulation
batch_size: 32 # batch size for the forward
gpus: null # gpus adopted
wandb_name: null # needed for wandb logging
resume_from: null # checkpoint directory
logname: null # name of the logs
models_dir: null # directory containing all the models

train:
  num_iter: 5000 # number of training iterations with total_batch size
  lr_steps: 3000 # steps before reducing learning rate
  eval_freq: 50 # evaluation frequency
  num_clips: 5 # clips adopted in training
  dense_sampling: # sampling version adopted in training for each modality
    RGB: True
  num_frames_per_clip: # number of frames adopted in training for each modality
    RGB: 16

test:
  num_clips: 5 # number of clips in testing
  dense_sampling: # sampling version adopted in test for each modality
    RGB: True
  num_frames_per_clip: # number of frames adopted in test for each modality
    RGB: 16

dataset:
  annotations_path: train_val # path for the annotations data
  shift: ??? # shifts of the dataset
  workers: 4 # number of workers for the dataloader
  stride: 2 # stride in case of dense sampling
  resolution: 224 # input resolution to the model
  RGB:
    data_path: ??? # path to RGB data
    tmpl: "img_{:010d}.jpg" # format of RGB filenames
    features_name: saved_feat_I3D
  Event: # not neeeded for the project
    rgb4e: 6

# these are the action recognition models for each modality
models:
  RGB:
    model: Classifier
    normalize: False
    kwargs: {}
    lr_steps: 3000
    lr: 0.01
    sgd_momentum: 0.9
    weight_decay: 1e-7
    beta: 0.5
    avg_modality: Pooling # Pooling or TRN
    num_clips: 5
    num_classes: 8
    baseline_type: video # video or frame
    domain_adapt_strategy: ['GSD'] #GSD, GRD, GVD