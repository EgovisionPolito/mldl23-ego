{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from statistics import mean\n",
    "\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch\n",
    "from utils.loaders import EpicKitchensDataset\n",
    "from utils.args import args\n",
    "from utils.utils import pformat_dict\n",
    "import utils\n",
    "from utils.logger import logger\n",
    "import numpy as np\n",
    "import os\n",
    "import models as model_list\n",
    "import tasks\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_operations():\n",
    "    \"\"\"\n",
    "    parse all the arguments, generate the logger, check gpus to be used and wandb\n",
    "    \"\"\"\n",
    "    logger.info(\"Running with parameters: \" + pformat_dict(args, indent=1))\n",
    "\n",
    "    # this is needed for multi-GPUs systems where you just want to use a predefined set of GPUs\n",
    "    if args.gpus is not None:\n",
    "        logger.debug('Using only these GPUs: {}'.format(args.gpus))\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpus)\n",
    "\n",
    "    # wanbd logging configuration\n",
    "    if args.wandb_name is not None:\n",
    "        wandb.init(group=args.wandb_name, dir=args.wandb_dir)\n",
    "        wandb.run.name = args.name + \"_\" + args.shift.split(\"-\")[0] + \"_\" + args.shift.split(\"-\")[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(action_classifier, train_loader, val_loader, device, num_classes):\n",
    "    \"\"\"\n",
    "    function to train the model on the test set\n",
    "    action_classifier: Task containing the model to be trained\n",
    "    train_loader: dataloader containing the training data\n",
    "    val_loader: dataloader containing the validation data\n",
    "    device: device on which you want to test\n",
    "    num_classes: int, number of classes in the classification problem\n",
    "    \"\"\"\n",
    "    global training_iterations, modalities\n",
    "\n",
    "    data_loader_source = iter(train_loader)\n",
    "    action_classifier.train(True)\n",
    "    action_classifier.zero_grad()\n",
    "    iteration = action_classifier.current_iter * (args.total_batch // args.batch_size)\n",
    "\n",
    "    # the batch size should be total_batch but batch accumulation is done with batch size = batch_size.\n",
    "    # real_iter is the number of iterations if the batch size was really total_batch\n",
    "    for i in range(iteration, training_iterations):\n",
    "        # iteration w.r.t. the paper (w.r.t the bs to simulate).... i is the iteration with the actual bs( < tot_bs)\n",
    "        real_iter = (i + 1) / (args.total_batch // args.batch_size)\n",
    "        if real_iter == args.train.lr_steps:\n",
    "            # learning rate decay at iteration = lr_steps\n",
    "            action_classifier.reduce_learning_rate()\n",
    "        # gradient_accumulation_step is a bool used to understand if we accumulated at least total_batch\n",
    "        # samples' gradient\n",
    "        gradient_accumulation_step = real_iter.is_integer()\n",
    "\n",
    "        \"\"\"\n",
    "        Retrieve the data from the loaders\n",
    "        \"\"\"\n",
    "        start_t = datetime.now()\n",
    "        # the following code is necessary as we do not reason in epochs so as soon as the dataloader is finished we need\n",
    "        # to redefine the iterator\n",
    "        try:\n",
    "            source_data, source_label = next(data_loader_source)\n",
    "        except StopIteration:\n",
    "            data_loader_source = iter(train_loader)\n",
    "            source_data, source_label = next(data_loader_source)\n",
    "        end_t = datetime.now()\n",
    "\n",
    "        logger.info(f\"Iteration {i}/{training_iterations} batch retrieved! Elapsed time = \"\n",
    "                    f\"{(end_t - start_t).total_seconds() // 60} m {(end_t - start_t).total_seconds() % 60} s\")\n",
    "\n",
    "        ''' Action recognition'''\n",
    "        source_label = source_label.to(device)\n",
    "        data = {}\n",
    "\n",
    "        for clip in range(args.train.num_clips):\n",
    "            # in case of multi-clip training one clip per time is processed\n",
    "            for m in modalities:\n",
    "                data[m] = source_data[m][:, clip].to(device)\n",
    "\n",
    "            logits, _ = action_classifier.forward(data)\n",
    "            action_classifier.compute_loss(logits, source_label, loss_weight=1)\n",
    "            action_classifier.backward(retain_graph=False)\n",
    "            action_classifier.compute_accuracy(logits, source_label)\n",
    "\n",
    "        # update weights and zero gradients if total_batch samples are passed\n",
    "        if gradient_accumulation_step:\n",
    "            logger.info(\"[%d/%d]\\tlast Verb loss: %.4f\\tMean verb loss: %.4f\\tAcc@1: %.2f%%\\tAccMean@1: %.2f%%\" %\n",
    "                        (real_iter, args.train.num_iter, action_classifier.loss.val, action_classifier.loss.avg,\n",
    "                         action_classifier.accuracy.val[1], action_classifier.accuracy.avg[1]))\n",
    "\n",
    "            action_classifier.check_grad()\n",
    "            action_classifier.step()\n",
    "            action_classifier.zero_grad()\n",
    "\n",
    "        # every eval_freq \"real iteration\" (iterations on total_batch) the validation is done, notice we validate and\n",
    "        # save the last 9 models\n",
    "        if gradient_accumulation_step and real_iter % args.train.eval_freq == 0:\n",
    "            val_metrics = validate(action_classifier, val_loader, device, int(real_iter), num_classes)\n",
    "\n",
    "            if val_metrics['top1'] <= action_classifier.best_iter_score:\n",
    "                logger.info(\"New best accuracy {:.2f}%\"\n",
    "                            .format(action_classifier.best_iter_score))\n",
    "            else:\n",
    "                logger.info(\"New best accuracy {:.2f}%\".format(val_metrics['top1']))\n",
    "                action_classifier.best_iter = real_iter\n",
    "                action_classifier.best_iter_score = val_metrics['top1']\n",
    "\n",
    "            action_classifier.save_model(real_iter, val_metrics['top1'], prefix=None)\n",
    "            action_classifier.train(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, device, it, num_classes):\n",
    "    \"\"\"\n",
    "    function to validate the model on the test set\n",
    "    model: Task containing the model to be tested\n",
    "    val_loader: dataloader containing the validation data\n",
    "    device: device on which you want to test\n",
    "    it: int, iteration among the training num_iter at which the model is tested\n",
    "    num_classes: int, number of classes in the classification problem\n",
    "    \"\"\"\n",
    "    global modalities\n",
    "\n",
    "    model.reset_acc()\n",
    "    model.train(False)\n",
    "    logits = {}\n",
    "\n",
    "    # Iterate over the models\n",
    "    with torch.no_grad():\n",
    "        for i_val, (data, label) in enumerate(val_loader):\n",
    "            label = label.to(device)\n",
    "\n",
    "            for m in modalities:\n",
    "                batch = data[m].shape[0]\n",
    "                logits[m] = torch.zeros((args.test.num_clips, batch, num_classes)).to(device)\n",
    "\n",
    "            clip = {}\n",
    "            for i_c in range(args.test.num_clips):\n",
    "                for m in modalities:\n",
    "                    clip[m] = data[m][:, i_c].to(device)\n",
    "\n",
    "                output, _ = model(clip)\n",
    "                for m in modalities:\n",
    "                    logits[m][i_c] = output[m]\n",
    "\n",
    "            for m in modalities:\n",
    "                logits[m] = torch.mean(logits[m], dim=0)\n",
    "\n",
    "            model.compute_accuracy(logits, label)\n",
    "\n",
    "            if (i_val + 1) % (len(val_loader) // 5) == 0:\n",
    "                logger.info(\"[{}/{}] top1= {:.3f}% top5 = {:.3f}%\".format(i_val + 1, len(val_loader),\n",
    "                                                                          model.accuracy.avg[1], model.accuracy.avg[5]))\n",
    "\n",
    "        class_accuracies = [(x / y) * 100 for x, y in zip(model.accuracy.correct, model.accuracy.total)]\n",
    "        logger.info('Final accuracy: top1 = %.2f%%\\ttop5 = %.2f%%' % (model.accuracy.avg[1],\n",
    "                                                                      model.accuracy.avg[5]))\n",
    "        for i_class, class_acc in enumerate(class_accuracies):\n",
    "            logger.info('Class %d = [%d/%d] = %.2f%%' % (i_class,\n",
    "                                                         int(model.accuracy.correct[i_class]),\n",
    "                                                         int(model.accuracy.total[i_class]),\n",
    "                                                         class_acc))\n",
    "\n",
    "    logger.info('Accuracy by averaging class accuracies (same weight for each class): {}%'\n",
    "                .format(np.array(class_accuracies).mean(axis=0)))\n",
    "    test_results = {'top1': model.accuracy.avg[1], 'top5': model.accuracy.avg[5],\n",
    "                    'class_accuracies': np.array(class_accuracies)}\n",
    "\n",
    "    with open(os.path.join(args.log_dir, f'val_precision_{args.dataset.shift.split(\"-\")[0]}-'\n",
    "                                         f'{args.dataset.shift.split(\"-\")[-1]}.txt'), 'a+') as f:\n",
    "        f.write(\"[%d/%d]\\tAcc@top1: %.2f%%\\n\" % (it, args.train.num_iter, test_results['top1']))\n",
    "\n",
    "    return test_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global training_iterations, modalities\n",
    "    init_operations()\n",
    "    modalities = args.modality\n",
    "\n",
    "    # recover valid paths, domains, classes\n",
    "    # this will output the domain conversion (D1 -> 8, et cetera) and the label list\n",
    "    num_classes, valid_labels, source_domain, target_domain = utils.utils.get_domains_and_labels(args)\n",
    "    # device where everything is run\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # these dictionaries are for more multi-modal training/testing, each key is a modality used\n",
    "    models = {}\n",
    "    logger.info(\"Instantiating models per modality\")\n",
    "    for m in modalities:\n",
    "        logger.info('{} Net\\tModality: {}'.format(args.models[m].model, m))\n",
    "        # notice that here, the first parameter passed is the input dimension\n",
    "        # In our case it represents the feature dimensionality which is equivalent to 1024 for I3D\n",
    "        models[m] = getattr(model_list, args.models[m].model)()\n",
    "\n",
    "    # the models are wrapped into the ActionRecognition task which manages all the training steps\n",
    "    action_classifier = tasks.ActionRecognition(\"action-classifier\", models, args.batch_size,\n",
    "                                                args.total_batch, args.models_dir, num_classes,\n",
    "                                                args.train.num_clips, args.models, args=args)\n",
    "    action_classifier.load_on_gpu(device)\n",
    "\n",
    "    if args.action == \"train\":\n",
    "        # resume_from argument is adopted in case of restoring from a checkpoint\n",
    "        if args.resume_from is not None:\n",
    "            action_classifier.load_last_model(args.resume_from)\n",
    "        # define number of iterations I'll do with the actual batch: we do not reason with epochs but with iterations\n",
    "        # i.e. number of batches passed\n",
    "        # notice, here it is multiplied by tot_batch/batch_size since gradient accumulation technique is adopted\n",
    "        training_iterations = args.train.num_iter * (args.total_batch // args.batch_size)\n",
    "        # all dataloaders are generated here\n",
    "        train_loader = torch.utils.data.DataLoader(EpicKitchensDataset(args.dataset.shift.split(\"-\")[0], modalities,\n",
    "                                                                       'train', args.dataset, None, None, None,\n",
    "                                                                       None, load_feat=True),\n",
    "                                                   batch_size=args.batch_size, shuffle=True,\n",
    "                                                   num_workers=args.dataset.workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(EpicKitchensDataset(args.dataset.shift.split(\"-\")[-1], modalities,\n",
    "                                                                     'val', args.dataset, None, None, None,\n",
    "                                                                     None, load_feat=True),\n",
    "                                                 batch_size=args.batch_size, shuffle=False,\n",
    "                                                 num_workers=args.dataset.workers, pin_memory=True, drop_last=False)\n",
    "        train(action_classifier, train_loader, val_loader, device, num_classes)\n",
    "\n",
    "    elif args.action == \"validate\":\n",
    "        if args.resume_from is not None:\n",
    "            action_classifier.load_last_model(args.resume_from)\n",
    "        val_loader = torch.utils.data.DataLoader(EpicKitchensDataset(args.dataset.shift.split(\"-\")[-1], modalities,\n",
    "                                                                     'val', args.dataset, None, None, None,\n",
    "                                                                     None, load_feat=True),\n",
    "                                                 batch_size=args.batch_size, shuffle=False,\n",
    "                                                 num_workers=args.dataset.workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "        validate(action_classifier, val_loader, device, action_classifier.current_iter, num_classes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
